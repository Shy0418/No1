{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                     0\n0          12 月 30 日武汉出现不明原因肺炎，目前情况如何？\n1                2019 年，你的「至暗时刻」是什么时候？\n2        大学生活有个讨厌的舍友，又碍于面子没法撕逼是怎样一种体验？\n3                      全职妈妈最终真的会成为悲剧吗？\n4             总结2019，展望2020！(附商誉地雷股名单)\n...                                ...\n598550                        为什么那么焦虑？\n598551     塞维中场：我对米兰非常感兴趣，从小就梦想为红黑军团效力\n598552  华晨宇真的没有团队吗？为什么部分人坚定地认为华晨宇没有团队？\n598553                         详细的自我介绍\n598554             如此恶心的操作，是奥克斯的常规操作吗？\n\n[598555 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12 月 30 日武汉出现不明原因肺炎，目前情况如何？</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019 年，你的「至暗时刻」是什么时候？</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>大学生活有个讨厌的舍友，又碍于面子没法撕逼是怎样一种体验？</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>全职妈妈最终真的会成为悲剧吗？</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>总结2019，展望2020！(附商誉地雷股名单)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>598550</th>\n      <td>为什么那么焦虑？</td>\n    </tr>\n    <tr>\n      <th>598551</th>\n      <td>塞维中场：我对米兰非常感兴趣，从小就梦想为红黑军团效力</td>\n    </tr>\n    <tr>\n      <th>598552</th>\n      <td>华晨宇真的没有团队吗？为什么部分人坚定地认为华晨宇没有团队？</td>\n    </tr>\n    <tr>\n      <th>598553</th>\n      <td>详细的自我介绍</td>\n    </tr>\n    <tr>\n      <th>598554</th>\n      <td>如此恶心的操作，是奥克斯的常规操作吗？</td>\n    </tr>\n  </tbody>\n</table>\n<p>598555 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhihu_question = pd.read_csv(r'E:\\pythonProject\\制作趋势词典\\知乎问题数据集.csv',encoding='utf-8',header=0,index_col=0,sep=r',',engine='python')\n",
    "zhihu_question\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# zhihu_samples = zhihu_question.sample(10000)\n",
    "zhihu = zhihu_question['0'].to_list()\n",
    "len(zhihu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['爱一个人',\n '表白',\n '初恋',\n '单身',\n '对象',\n '恩爱',\n '放电',\n '夫妻',\n '告白',\n '红颜',\n '婚后',\n '婚庆',\n '婚纱',\n '婚纱照',\n '佳人',\n '嫁人',\n '接吻',\n '戒指',\n '恋情',\n '玫瑰',\n '玫瑰花',\n '你是我的',\n '娘子',\n '妻子',\n '牵手',\n '情侣',\n '情人节',\n '情书',\n '求婚',\n '热恋',\n '失恋',\n '誓言',\n '守候',\n '私奔',\n '谈恋爱',\n '桃花运',\n '天天情人节',\n '脱光',\n '相爱',\n '相亲',\n '相约',\n '邂逅',\n '新婚',\n '新郎',\n '新娘',\n '新人',\n '一对',\n '一见钟情',\n '一生一世',\n '因为爱情',\n '缘分',\n '钻戒',\n '爱上',\n '爱意',\n '痴情',\n '动心',\n '归宿',\n '好感',\n '花心',\n '刻骨铭心',\n '情缘',\n '撒娇',\n '守护',\n '随缘',\n '我喜欢你',\n '无缘',\n '相思',\n '心动',\n '心仪',\n '有情',\n '缘份',\n '挚爱',\n '专一',\n '追求',\n '最爱你',\n '爱国',\n '爱美',\n '安定',\n '安全感',\n '安然',\n '安神',\n '安慰',\n '傲娇',\n '霸道',\n '霸气',\n '白嫩',\n '白眼',\n '包袱',\n '包容',\n '饱满',\n '保守',\n '保重',\n '卑微',\n '悲哀',\n '悲惨',\n '悲观',\n '悲剧',\n '被盗',\n '本能',\n '本色',\n '本事',\n '本土',\n '本性',\n '崩溃',\n '鄙视',\n '变色',\n '变态',\n '便捷',\n '便利',\n '标志',\n '表态',\n '别扭',\n '别致',\n '缤纷',\n '冰凉',\n '不懂',\n '不二',\n '不凡',\n '不负',\n '不公',\n '不规则',\n '不好',\n '不好意思',\n '不和',\n '不简单',\n '不禁',\n '不堪',\n '不肯',\n '不快',\n '不愧',\n '不赖',\n '不如意',\n '不顺',\n '不惜',\n '不屑',\n '不信',\n '不要紧',\n '不要脸',\n '不易',\n '不在乎',\n '不知',\n '猜猜',\n '惭愧',\n '草草',\n '超大',\n '超强',\n '超脱',\n '吵架',\n '沉浸',\n '沉闷',\n '沉稳',\n '沉醉',\n '称为',\n '成全',\n '诚信',\n '诚意',\n '承受',\n '逞强',\n '吃苦',\n '吃亏',\n '尺寸',\n '耻辱',\n '冲动',\n '充实',\n '憧憬',\n '惆怅',\n '臭美',\n '出头',\n '出众',\n '穿越',\n '传递',\n '传来',\n '创意',\n '吹牛',\n '纯洁',\n '纯净',\n '纯情',\n '纯色',\n '纯真',\n '凑合',\n '催眠',\n '璀璨',\n '错觉',\n '错了',\n '打动',\n '打雷',\n '大大的',\n '大度',\n '大好',\n '大红',\n '大话',\n '大吉',\n '大哭',\n '大美',\n '大气',\n '大小',\n '担当',\n '单调',\n '胆子',\n '淡淡',\n '淡化',\n '淡然',\n '淡忘',\n '淡雅',\n '当成',\n '当心',\n '当作',\n '当做',\n '到位',\n '道德',\n '得了',\n '得知',\n '低调',\n '低下',\n '抵抗',\n '底线',\n '地瓜',\n '第一次',\n '典雅',\n '点滴',\n '点头',\n '惦记',\n '顶级',\n '鼎力支持',\n '懂得',\n '懂事',\n '动感',\n '动力',\n '独立',\n '独特',\n '妒忌',\n '对不起',\n '对得起',\n '多谢',\n '恶意',\n '噩梦',\n '而不',\n '二次元',\n '发达',\n '发呆',\n '发疯',\n '发火',\n '发脾气',\n '发誓',\n '发泄',\n '发自',\n '烦人',\n '烦躁',\n '繁华',\n '犯罪',\n '泛滥',\n '放手',\n '放下',\n '非凡',\n '沸水',\n '分成',\n '氛围',\n '粉嫩',\n '愤怒',\n '丰厚',\n '丰满',\n '丰盛',\n '风采',\n '风度',\n '风范',\n '风格',\n '风流',\n '风靡',\n '风情',\n '风骚',\n '风尚',\n '敷衍',\n '浮夸',\n '浮现',\n '浮云',\n '浮躁',\n '符合',\n '抚摸',\n '父爱',\n '负面',\n '赋予',\n '腹黑',\n '甘心',\n '赶紧',\n '感触',\n '感到',\n '感动',\n '感慨',\n '感人',\n '感叹',\n '感悟',\n '感想',\n '感性',\n '干杯',\n '干脆',\n '高档',\n '高楼',\n '高品质',\n '高尚',\n '高调',\n '搞笑',\n '格调',\n '个性',\n '公道',\n '公平',\n '公正',\n '恭喜',\n '共度',\n '共勉',\n '共鸣',\n '狗血',\n '孤单',\n '孤独',\n '孤寂',\n '辜负',\n '古典',\n '鼓掌',\n '怪物',\n '关爱',\n '关键',\n '关注',\n '观念',\n '观赏',\n '观望',\n '管用',\n '光彩',\n '光明',\n '光泽',\n '诡异',\n '贵阳',\n '贵在',\n '滚蛋',\n '过不去',\n '过度',\n '过人',\n '过头',\n '过瘾',\n '含泪',\n '含蓄',\n '毫不犹豫',\n '豪放',\n '好不容易',\n '好话',\n '好久',\n '好看',\n '好厉害',\n '好评',\n '好奇心',\n '好人',\n '好事',\n '好受',\n '好心',\n '好样',\n '好意思',\n '呵护',\n '喝彩',\n '何物',\n '和好',\n '黑白',\n '黑线',\n '嗨皮',\n '很有创意',\n '狠狠',\n '恨不得',\n '衡量',\n '轰轰烈烈',\n '红灯',\n '厚道',\n '胡闹',\n '胡思乱想',\n '糊涂',\n '花色',\n '花纹',\n '花香',\n '划算',\n '怀旧',\n '怀着',\n '欢呼',\n '欢喜',\n '欢笑',\n '缓解',\n '谎言',\n '回顾',\n '回眸',\n '回首',\n '回味',\n '会心',\n '慧眼',\n '豁达',\n '活该',\n '火爆',\n '获悉',\n '吉利',\n '吉祥',\n '吉祥如意',\n '急性',\n '急需',\n '嫉妒',\n '计较',\n '记性',\n '记忆力',\n '寄托',\n '寂寞',\n '加油',\n '价值观',\n '架子',\n '坚韧',\n '坚守',\n '坚信',\n '艰辛',\n '煎熬',\n '检讨',\n '减压',\n '简简单单',\n '简约',\n '见识',\n '见证',\n '健脾',\n '将就',\n '讲究',\n '觉醒',\n '节操',\n '洁白',\n '结实',\n '解读',\n '介意',\n '金色',\n '尽力',\n '尽情',\n '进取',\n '劲儿',\n '经不起',\n '经得起',\n '经典',\n '惊人',\n '惊喜',\n '惊险',\n '惊醒',\n '精明',\n '敬佩',\n '敬请',\n '静静',\n '静静的',\n '静静地',\n '纠缠',\n '纠结',\n '纠正',\n '久违',\n '眷顾',\n '眷恋',\n '绝情',\n '均衡',\n '君子',\n '咖啡店',\n '看不到',\n '看穿',\n '看待',\n '看得见',\n '看好',\n '看清',\n '看上',\n '看透',\n '看中',\n '看重',\n '抗拒',\n '可贵',\n '可恨',\n '可惜',\n '可惜了',\n '可以选择',\n '口感',\n '哭泣',\n '苦苦',\n '苦难',\n '夸奖',\n '夸张',\n '快感',\n '快捷',\n '宽广',\n '困惑',\n '困难',\n '来电',\n '懒得',\n '懒得理',\n '牢记',\n '老实',\n '乐观',\n '乐趣',\n '了得',\n '泪水',\n '冷落',\n '冷漠',\n '冷笑',\n '冷战',\n '里加',\n '理念',\n '理所当然',\n '力度',\n '立体',\n '立志',\n '励志',\n '利于',\n '联系方式',\n '联想',\n '脸红',\n '脸皮',\n '良心',\n '良知',\n '凉爽',\n '凉水',\n '亮丽',\n '谅解',\n '靓丽',\n '灵动',\n '留恋',\n '流畅',\n '乱七八糟',\n '轮廓',\n '落泪',\n '麻辣',\n '满怀',\n '漫漫',\n '慢慢',\n '茫茫',\n '貌似',\n '没错',\n '没事',\n '没意思',\n '没用',\n '没有用',\n '美感',\n '美观',\n '美貌',\n '美美',\n '美梦',\n '妹子',\n '梦幻',\n '梦见',\n '梦境',\n '弥补',\n '迷糊',\n '迷茫',\n '迷你',\n '米色',\n '绵绵',\n '缅怀',\n '面对',\n '面子',\n '渺茫',\n '明媚',\n '铭记',\n '膜拜',\n '磨难',\n '莫名',\n '莫名其妙',\n '默默',\n '默契',\n '母爱',\n '奈何',\n '耐心',\n '难看',\n '难受',\n '难听',\n '难忘',\n '难为',\n '脑海',\n '内涵',\n '内向',\n '内心',\n '能量',\n '尼玛',\n '逆境',\n '念念不忘',\n '念头',\n '浓浓的',\n '浓郁',\n '怒骂',\n '懦弱',\n '排名',\n '攀比',\n '叛逆',\n '胖胖',\n '咆哮',\n '陪伴',\n '佩服',\n '配色',\n '霹雳',\n '骗人',\n '飘逸',\n '品位',\n '品味',\n '品质',\n '平常心',\n '平淡',\n '平等',\n '平衡',\n '平平安安',\n '七彩',\n '欺负',\n '欺骗',\n '奇迹',\n '奇妙',\n '奇葩',\n '奇异',\n '祈福',\n '气势',\n '气质',\n '迁就',\n '谦虚',\n '潜能',\n '强悍',\n '强行',\n '强化',\n '强劲',\n '强求',\n '强势',\n '抢眼',\n '悄然',\n '憔悴',\n '巧合',\n '巧妙',\n '切记',\n '惬意',\n '亲情',\n '禽兽',\n '勤劳',\n '青睐',\n '轻薄',\n '轻易',\n '轻盈',\n '清澈',\n '清纯',\n '清淡',\n '清香',\n '情不自禁',\n '情感',\n '情怀',\n '情结',\n '情趣',\n '情调',\n '情绪化',\n '情谊',\n '情愿',\n '庆幸',\n '曲折',\n '取悦',\n '缺点',\n '却说',\n '热心',\n '人格',\n '人和',\n '人品',\n '人味',\n '人心',\n '人性',\n '人性化',\n '人缘',\n '忍不住',\n '忍耐',\n '忍让',\n '忍心',\n '认错',\n '认得',\n '认定',\n '认同',\n '日日',\n '容貌',\n '融入',\n '柔美',\n '柔情',\n '如意',\n '睿智',\n '弱势',\n '弱智',\n '洒脱',\n '色调',\n '色系',\n '色泽',\n '闪闪',\n '善解人意',\n '善于',\n '伤不起',\n '伤痕',\n '上好',\n '奢侈',\n '奢望',\n '舍不得',\n '舍得',\n '身为',\n '身心',\n '深层',\n '深沉',\n '深刻',\n '深受',\n '神奇',\n '升华',\n '生活态度',\n '盛大',\n '失落',\n '失意',\n '湿润',\n '十全十美',\n '使命',\n '世故',\n '世界观',\n '视角',\n '视觉',\n '是非',\n '适度',\n '适用于',\n '室温',\n '释怀',\n '收敛',\n '手感',\n '受益',\n '舒缓',\n '舒坦',\n '熟悉',\n '衰老',\n '水温',\n '顺其自然',\n '顺心',\n '说法',\n '说实话',\n '思路',\n '思维',\n '思想',\n '思绪',\n '素质',\n '缩小',\n '踏实',\n '态度',\n '谈谈',\n '坦然',\n '叹息',\n '讨好',\n '特地',\n '特色',\n '特意',\n '特征',\n '特质',\n '提神',\n '天理',\n '天性',\n '天真',\n '甜甜',\n '调料',\n '调调',\n '贴切',\n '贴心',\n '听话',\n '听听',\n '同感',\n '同在',\n '童心',\n '童真',\n '痛快',\n '偷偷',\n '透彻',\n '透明',\n '透视',\n '突发',\n '吐槽',\n '吐血',\n '团结',\n '推荐',\n '颓废',\n '外形',\n '完蛋',\n '挽回',\n '万恶',\n '万能',\n '万事如意',\n '忘掉',\n '忘却',\n '旺盛',\n '危机',\n '威武',\n '微妙',\n '围观',\n '伪装',\n '委屈',\n '猥琐',\n '味儿',\n '温度',\n '稳定',\n '稳重',\n '我会',\n '我靠',\n '我要做',\n '污染',\n '无悔',\n '无理取闹',\n '无奈',\n '无能为力',\n '无私',\n '无所谓',\n '无心',\n '无言',\n '无语',\n '五彩',\n '误区',\n '吸引力',\n '稀罕',\n '犀利',\n '习惯性',\n '喜怒哀乐',\n '喜庆',\n '喜悦',\n '细腻',\n '细细',\n '细致',\n '吓人',\n '仙子',\n '先进',\n '贤惠',\n '嫌弃',\n '相伴',\n '相见',\n '相知',\n '香肠',\n '香甜',\n '享乐',\n '享受生活',\n '想不到',\n '想当年',\n '想到',\n '想法',\n '想见',\n '想起',\n '想想',\n '想象力',\n '想像',\n '逍遥',\n '销魂',\n '潇洒',\n '嚣张',\n '小动作',\n '小人',\n '小声',\n '小样',\n '笑哈哈',\n '笑声',\n '心得',\n '心底',\n '心地',\n '心烦',\n '心扉',\n '心甘情愿',\n '心机',\n '心计',\n '心境',\n '心目',\n '心软',\n '心上',\n '心声',\n '心事',\n '心态',\n '心疼',\n '心头',\n '心想',\n '心想事成',\n '心胸',\n '心眼',\n '心意',\n '心愿',\n '心中',\n '辛苦',\n '欣慰',\n '形态',\n '醒来',\n '幸福感',\n '幸福生活',\n '幸好',\n '幸亏',\n '幸运儿',\n '性格',\n '凶残',\n '胸怀',\n '胸襟',\n '修炼',\n '修身',\n '修养',\n '羞涩',\n '虚假',\n '虚伪',\n '需求',\n '许愿',\n '喧嚣',\n '绚丽',\n '严肃',\n '炎热',\n '掩饰',\n '眼光',\n '眼熟',\n '厌倦',\n '洋气',\n '洋溢',\n '妖娆',\n '妖艳',\n '要命',\n '一不小心',\n '一度',\n '一模一样',\n '一念',\n '一切顺利',\n '一塌糊涂',\n '一心',\n '义气',\n '异常',\n '异味',\n '意见',\n '意境',\n '意料',\n '意识',\n '意味着',\n '意想不到',\n '意义',\n '意愿',\n '因为你',\n '阴霾',\n '阴险',\n '阴影',\n '音符',\n '银色',\n '隐忍',\n '隐形',\n '隐隐',\n '拥挤',\n '慵懒',\n '勇于',\n '优质',\n '忧愁',\n '忧虑',\n '悠悠',\n '有多少',\n '有感',\n '有机会赢取',\n '有理',\n '有利于',\n '有事',\n '有望',\n '有心',\n '有幸',\n '有意',\n '有意思',\n '有种',\n '右手',\n '幼稚',\n '诱人',\n '愉悦',\n '与众不同',\n '语音',\n '郁闷',\n '预测',\n '预感',\n '愈合',\n '冤枉',\n '圆满',\n '韵味',\n '在我身边',\n '在心',\n '在意',\n '责任感',\n '张扬',\n '掌声',\n '折腾',\n '褶皱',\n '这般',\n '着急',\n '着实',\n '着想',\n '真诚的',\n '真谛',\n '真好',\n '真话',\n '真情',\n '真心话',\n '真挚',\n '震荡',\n '震撼',\n '争气',\n '整合',\n '正经',\n '正义',\n '正直',\n '支持你',\n '只怕',\n '知心',\n '知性',\n '执着',\n '执著',\n '直觉',\n '直视',\n '值得拥有',\n '指出',\n '指点',\n '志趣',\n '志愿',\n '质感',\n ...]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "seed_words1 = pd.read_excel(r'E:\\论文\\数据\\WenXinV4.0师姐发的版本\\dic\\dictionary_all.xlsx',header=0,index_col=None)\n",
    "seed_words1\n",
    "seed_words = seed_words1['words'].to_list()\n",
    "seed_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(seed_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jieba.load_userdict(r'E:\\pythonProject\\制作趋势词典\\dictionary.txt')\n",
    "def tokenize_zh(text):\n",
    "    words = jieba.lcut(text)\n",
    "    return words\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_zh)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 这段不要随便跑\n",
    "from keybert import KeyBERT\n",
    "kw_model =  KeyBERT('all-MiniLM-L6-v2')\n",
    "count = 0\n",
    "path_keybert = r'Keybert抽取关键词.txt'\n",
    "with open(path_keybert,mode='w+',encoding='utf-8') as file_keybert:\n",
    "    for i in zhihu:\n",
    "        keywords = kw_model.extract_keywords(i,vectorizer=vectorizer,stop_words='E:\\论文\\python代码\\停用词表\\stopwords_all.txt',keyphrase_ngram_range=[1,2],use_maxsum=False,use_mmr=False,top_n = 3,seed_keywords = seed_words)\n",
    "        for j in range(len(keywords)):\n",
    "            # print(j)\n",
    "            file_keybert.write(str(keywords[j][0]+'\\t'))\n",
    "        file_keybert.write('\\n')\n",
    "        # print(keywords[0][0])\n",
    "        # print(keywords[1][0])\n",
    "        print(count)\n",
    "        count+=1\n",
    "# file_keybert.flush()\n",
    "file_keybert.close()\n",
    "time_end = datetime.datetime.now()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "data = pd.read_table(r'E:\\pythonProject\\制作趋势词典\\Keybert抽取关键词.txt',encoding='utf-8',header=None,sep='\\t',quoting=csv.QUOTE_NONE)\n",
    "data1 = data.iloc[:,0:3]\n",
    "data1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data2 = np.array(data1)\n",
    "data2\n",
    "data3 = data2.reshape(1795665,1)\n",
    "data3\n",
    "pd.DataFrame(data3).to_csv(r'Keybert抽取关键词处理后.txt',encoding='utf-8',header=None,index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "stopwords = pd.read_table(r'E:\\pythonProject\\制作趋势词典\\stopwords_all.txt',encoding='utf-8',header=None,quoting=csv.QUOTE_NONE)\n",
    "stopwords1 = stopwords[0].tolist()\n",
    "stopwords1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 统计keybert抽取的关键词词频\n",
    "txt = open(r'E:\\pythonProject\\制作趋势词典\\Keybert抽取关键词处理后.txt', 'r',encoding='utf-8').readlines()    # 获取文本文件\n",
    "counts = {}    # 创建空字典\n",
    "for num in txt:\n",
    "    if num == ' ':    # 排除数字文本中可能出现的空格\n",
    "        continue\n",
    "    else:\n",
    "        counts[num] = counts.get(num, 0) + 1  # 统计词频并在字典中创建键值对\n",
    "items = list(counts.items())       # 将无序的字典类型转换为可排序的列表类型\n",
    "items.sort(key=lambda x: x[1], reverse=True)   # 以元素的第二列进行从大到小排序\n",
    "\n",
    "for i in range(10000):\n",
    "    num, count = items[i]\n",
    "    print(\"{:<5}:{:>5}\".format(num, count))    # 格式化输出排序结果\n",
    "    # print(num)\n",
    "    # print(type(num))\n",
    "    with open(r'Keybert提取前10000个关键词.txt',mode='a+',encoding='utf-8') as file:\n",
    "        if num not in stopwords1:\n",
    "            file.write(num)\n",
    "        else:\n",
    "            continue\n",
    "        # file.write('\\n')\n",
    "# file.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TF_IDF抽取\n",
    "path_tf_idf = r'TF_IDF抽取关键词.txt'\n",
    "import jieba  # 分词器\n",
    "import jieba.analyse\n",
    "import pandas as pd\n",
    "jieba.load_userdict(r'E:\\pythonProject\\制作趋势词典\\dictionary.txt')\n",
    "def tfidf_ana(content):\n",
    "    title_keys = jieba.analyse.extract_tags(content, topK=10000, withWeight=False)  # topK为期望得到的关键词个数\n",
    "    with open(path_tf_idf, mode='w+',encoding='utf-8') as file:\n",
    "        for i in title_keys:\n",
    "            file.write(i + '\\n')\n",
    "        # file.flush()\n",
    "        file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "answer_df = pd.read_csv('E:\\pythonProject\\制作趋势词典\\知乎问题数据集.csv',encoding='utf-8')\n",
    "answer_list = answer_df['0'].to_list()\n",
    "answer_str = ''\n",
    "i=0\n",
    "for k in answer_list:\n",
    "    print(i)\n",
    "    i+=1\n",
    "    answer_str += str(k)\n",
    "    print(k)\n",
    "data = tfidf_ana(answer_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = pd.read_table(r'E:\\pythonProject\\制作趋势词典\\TF-IDF+KeyBert未去重种子词.txt',encoding='utf-8',header=None)\n",
    "seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_words_unique=seed.iloc[:][0].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_words_unique1 = list(seed_words_unique)\n",
    "with open(r'去重后的种子词语.txt',encoding='utf-8',mode='w+') as file:\n",
    "    for i in seed_words_unique1:\n",
    "        if str(i) not in stopwords1:\n",
    "            file.write(str(i)+'\\n')\n",
    "        else:\n",
    "            continue\n",
    "file.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed_words_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[43mseed_words_unique\u001B[49m)\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mpythonProject\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m制作趋势词典\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m去重后的种子词语.txt\u001B[39m\u001B[38;5;124m'\u001B[39m,encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m,header\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mlen\u001B[39m(seed_words_unique)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'seed_words_unique' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(seed_words_unique).to_csv(r'E:\\pythonProject\\制作趋势词典\\去重后的种子词语.txt',encoding='utf-8',header=0,index=None)\n",
    "len(seed_words_unique)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from d:\\python3.8\\lib\\site-packages\\synonyms\\data\\vocab.txt ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Synonyms: v3.18.0, Project home: https://github.com/chatopera/Synonyms/\n",
      "\n",
      " Project Sponsored by Chatopera\n",
      "\n",
      "  deliver your chatbots with Chatopera Cloud Services --> https://bot.chatopera.com\n",
      "\n",
      ">> Synonyms load wordseg dict [d:\\python3.8\\lib\\site-packages\\synonyms\\data\\vocab.txt] ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache C:\\Users\\Shy0418\\AppData\\Local\\Temp\\jieba.u4ffff3a26e04aaea5c89ddb932e881e1.cache\n",
      "Loading model cost 1.439 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Synonyms on loading stopwords [d:\\python3.8\\lib\\site-packages\\synonyms\\data\\stopwords.txt] ...\n",
      ">> Synonyms on loading vectors [d:\\python3.8\\lib\\site-packages\\synonyms\\data\\words.vector.gz] ...\n"
     ]
    }
   ],
   "source": [
    "import synonyms\n",
    "# synonyms.display('问题')\n",
    "a = synonyms.nearby('问题',10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['问题', '1.0'],\n       ['难题', '0.6956479'],\n       ['缺陷', '0.63884103'],\n       ['弊端', '0.638318'],\n       ['环境问题', '0.624778'],\n       ['结构性问题', '0.613208'],\n       ['关键问题', '0.6061078'],\n       ['弊病', '0.60467'],\n       ['症结', '0.5877637'],\n       ['风险问题', '0.5795508']], dtype='<U32')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(a).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,LSTM,GRU,Embedding,Flatten,Bidirectional,Attention\n",
    "model = Sequential()\n",
    "# model.add(Embedding(input_dim=(64,32),batch_size=10,output_dim=(32,16)))\n",
    "model.add(Bidirectional(LSTM(units=64,input_dim=128,dropout=0.5)))\n",
    "model.add(Attention())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64,activation='relu',input_dim=32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=1,activation='relu'))\n",
    "model.add(Activation('softmax'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam,SGD,RMSprop\n",
    "model.compile(loss='categorcy_crossentropy',optimizer=Adam(lr=1e-5))\n",
    "# model.fit(x_train,y_train,nb_epoch=5,batch_size=10,epochs=100)\n",
    "# loss_and_metrics = model.evaluate(x_test,y_test,batch_size=100)\n",
    "# classes = model.predict(x_test,batch_size=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# model.built()\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32md:\\python3.8\\lib\\site-packages\\keras\\engine\\training.py:2869\u001B[0m, in \u001B[0;36mModel.summary\u001B[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001B[0m\n\u001B[0;32m   2847\u001B[0m \u001B[38;5;124;03m\"\"\"Prints a string summary of the network.\u001B[39;00m\n\u001B[0;32m   2848\u001B[0m \n\u001B[0;32m   2849\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2866\u001B[0m \u001B[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001B[39;00m\n\u001B[0;32m   2867\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2868\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuilt:\n\u001B[1;32m-> 2869\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2870\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThis model has not yet been built. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2871\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBuild the model first by calling `build()` or by calling \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2872\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe model on a batch of data.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   2873\u001B[0m layer_utils\u001B[38;5;241m.\u001B[39mprint_summary(\n\u001B[0;32m   2874\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   2875\u001B[0m     line_length\u001B[38;5;241m=\u001B[39mline_length,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2878\u001B[0m     expand_nested\u001B[38;5;241m=\u001B[39mexpand_nested,\n\u001B[0;32m   2879\u001B[0m     show_trainable\u001B[38;5;241m=\u001B[39mshow_trainable)\n",
      "\u001B[1;31mValueError\u001B[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# model.built()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}